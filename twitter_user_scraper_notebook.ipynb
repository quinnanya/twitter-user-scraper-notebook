{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter scraper for a user account\n",
    "This notebook uses the [Tweepy](https://www.tweepy.org/) library to scrape as many tweets as possible (up to 3,200) for a specified user, and export the text (and optionally, metadata) to a CSV file.\n",
    "\n",
    "## Prerequisites\n",
    "- Before you can use this notebook, you have to have a Twitter account, and use it to [apply for a developer account](https://developer.twitter.com/). The approval process usually takes a few days. \n",
    "- Once you've been approved for a developer account, you can [visit the app dashboard](https://developer.twitter.com/en/apps)\n",
    "- On the app dashboard, create a new app to use with this scraper. \n",
    "- After you've created your app, on the editing screen for the app there's a tab at the top for \"Keys and tokens\". Click on that tab. \n",
    "- On the page that appears, create an app token and app token secret. You'll need those values, along with the Consumer API Keys, in the second code block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0. Install Tweepy\n",
    "If you haven't installed Tweepy already, run the code block below to install it. You should only have to run this the very first time you use this notebook. If you run it again later, you'll just get a message that Tweepy is already installed (\"Requirement already satisfied\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Import libraries\n",
    "Every time you use this notebook, start by running the code block below to import the necessary libraries: *tweepy* for scraping tweets, *pandas* for storing the tweets in a form where we can easily choose what to export, *re* for cleaning the data, and *datetime* for grabbing the current date for the output filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Twitter API authentication\n",
    "Put the consumer key, consumer secret, access token, and access secret from the app that you created for use with this notebook between the quotation marks below, and run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"put-your-consumer-key-here\"\n",
    "consumer_secret = \"put-your-consumer-secret-here\"\n",
    "access_token = \"put-your-access-token-here\"\n",
    "access_secret = \"put-your-access-secret-here\"\n",
    " \n",
    "#Performs authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "#Defines API using the authentication info\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Specify the username\n",
    "Put the Twitter username of the user whose tweets you want to scrape between the quotes below, replacing `ADHOrg`. Don't use the @ sign. Run the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwitterHandle = 'ADHOrg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Scrape tweets\n",
    "Run the code cell below to start scraping. At some point, the Twitter API won't give you more results, and the code will wait 15 minutes before trying again.\n",
    "\n",
    "This scraper excludes replies from what it captures. If you want to include replies, change `exclude_replies=True` to `exclude_replies=False` in the line that begins `for tweet in tweepy.Cursor`.\n",
    "\n",
    "If you don't want the scraped tweets to print to the screen as they're gathered, you can put a `#` in front of the line `print(tempdata)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now()\n",
    "endtime = now + datetime.timedelta(minutes = 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List for collecting lists containing the tweet information\n",
    "tweetholder = []\n",
    "#This will iterate indefinitely to try to get more tweets\n",
    "\n",
    "#while now < endtime:\n",
    "while True:\n",
    "    try:\n",
    "        #Looks in the Twitter timeline for the user with the user name you specified above\n",
    "        for tweet in tweepy.Cursor(api.user_timeline, screen_name=TwitterHandle, exclude_replies=True, tweet_mode=\"extended\", wait_on_rate_limit=True).items():\n",
    "            #\n",
    "            tweet_text = tweet.full_text  \n",
    "            time = tweet.created_at  \n",
    "            tweeter = tweet.user.screen_name\n",
    "            tweetid = tweet.id\n",
    "            tempdata = [tweet.id, tweet.user.screen_name, str(tweet.created_at), tweet.full_text]\n",
    "            tweetholder.append(tempdata)\n",
    "            print(tempdata)\n",
    "    except tweepy.RateLimitError:\n",
    "        time.sleep(15 * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5. Put the tweets in a dataframe\n",
    "Run the code block below to turn the *tweetholder* list into a dataframe that's easier to export fom and modify, and display the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame(tweetholder, columns=['tweetid','username','timestamp','tweet_text'])\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Clean data\n",
    "If we want to use these tweets for text analysis, it may help to remove URLs, which will probably only occur once. Run the cell below to remove URLs from the *tweet_text* column of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['tweet_text'] = df3['tweet_text'].str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7. Export data\n",
    "Run the code cells below to export the data in two formats: one with just the text of the tweets, and another with all the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets up a variable for the current time, to append to the end of the filename\n",
    "#That makes it easier to avoid a lot of fles with duplicate names if you run the code multiple times\n",
    "time = datetime.datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7a. Export only tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifies an output filename based on the twitter username captured, plus current time\n",
    "outtweets = TwitterHandle + \"-tweets-\" + time + \".csv\"\n",
    "#Exports ONLY TWEET TEXT to a CSV file\n",
    "df3.to_csv(outtweets, mode='w', columns=['tweet_text'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7b. Export tweets + metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specifies an output filename based on the twitter username captured, plus current time\n",
    "outtweetsmetadata = TwitterHandle + \"-tweets-metadata-\" + time + \".csv\"\n",
    "#Exports all columns from the dataframe to a CSV file\n",
    "df3.to_csv(outtweetsmetadata, mode='w', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested citation\n",
    "Dombrowski, Quinn. *Twitter scraper for a user account*. Jupyter Notebook. https://github.com/quinnanya/twitter-user-scraper-notebook. December 19, 2019."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
